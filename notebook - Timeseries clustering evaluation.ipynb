{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Clustering Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from math import ceil\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.offline as po\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tools\n",
    "import colorlover as cl\n",
    "#from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "\n",
    "import matplotlib. pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "from features.feature_ts import *\n",
    "import evaluation.clusteval as ce\n",
    "from observations.obs_processing import *\n",
    "from support import data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Results\n",
    "\n",
    "Fetch results from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results = ce.readResults()\n",
    "cluster_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotClusterIndex(index, title, ylog=False):\n",
    "    experiments = cluster_results.experiment_name.unique()\n",
    "    colours = dict(zip(experiments, cl.scales[str(len(experiments))]['qual']['Paired']))\n",
    "    df = cluster_results.set_index(['experiment_name','series'])[[index,'clusters']]\n",
    "    data = pd.pivot_table(df[[index,'clusters']], index='clusters', columns=df.index, values=index)\n",
    "\n",
    "    #generate plot data\n",
    "    traces = []\n",
    "    for c in data.columns:\n",
    "        x = data.index\n",
    "        y = data[c]\n",
    "        n = '_'.join([c[0].split('_',1)[1],str(c[1])])\n",
    "        hovertext = list()\n",
    "        for i in x:\n",
    "            hovertext.append('{}<br />{}: {:.3f}<br />{} clusters<br />'.format(n, index, y[i], i))\n",
    "\n",
    "        traces.append(dict(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            name=n,\n",
    "            legendgroup=c[0].split('_',1)[1],\n",
    "            mode='lines+markers',\n",
    "            marker=dict(size=3),\n",
    "            line=dict(color=colours[c[0]]),\n",
    "            text = hovertext,\n",
    "            hoverinfo='text',\n",
    "            connectgaps=True\n",
    "        ))\n",
    "\n",
    "    #set layout\n",
    "    if ylog == True:\n",
    "        yax = dict(title = index+' (log scale)' , type='log')\n",
    "    else:\n",
    "        yax = dict(title = index)\n",
    "    layout = go.Layout(\n",
    "            title= title,\n",
    "            margin=go.Margin(t=50,r=50,b=50,l=50, pad=10),\n",
    "            height= 700,\n",
    "            xaxis=dict(title = 'clusters (log scale)', type='log'),\n",
    "            yaxis=yax,\n",
    "            hovermode = \"closest\"\n",
    "            )\n",
    "\n",
    "    fig = {'data':traces, 'layout':layout }\n",
    "    return po.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Davies-Bouldin Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotClusterIndex('dbi', 'Davies-Bouldin Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Index Adequacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotClusterIndex('mia','Mean Index Adequacy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette Score\n",
    "\n",
    "The best value is 1 and the worst value is -1. Values near 0 indicate overlapping clusters. Negative values generally indicate that a sample has been assigned to the wrong cluster, as a different cluster is more similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotClusterIndex('silhouette', 'Silhouette Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Best Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotClusterIndex('score','Combined Cluster Score',ylog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demin_clusters = ce.selectClusters(cluster_results, 5, 'exp2_kmeans_demin')\n",
    "zerone_clusters = ce.selectClusters(cluster_results, 5, 'exp2_kmeans_zero-one')\n",
    "sanorm_clusters = ce.selectClusters(cluster_results, 5, 'exp2_kmeans_sa_norm')\n",
    "best_clusters = ce.selectClusters(cluster_results, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Best Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotClusterCentroids(best_clusters, n_best=1):\n",
    "    \n",
    "    best_experiments = list(best_clusters.experiment_name.unique())\n",
    "    centroid_files = dict(zip(best_experiments,[e+'_centroids.csv' for e in best_experiments]))\n",
    "    centroids = {}\n",
    "    for k, v in centroid_files.items():\n",
    "        centroids[k] = pd.read_csv(os.path.join(data_dir, 'cluster_results', v))\n",
    "    \n",
    "    best_centroids = pd.DataFrame()\n",
    "    for row in best_clusters.itertuples():\n",
    "        df = centroids[row.experiment_name]\n",
    "        c = df.loc[(df.som_dim==row.som_dim)&(df.n_clust==row.n_clust),:]\n",
    "        best_centroids = best_centroids.append(c)\n",
    "    best_centroids.drop_duplicates(subset=['som_dim','n_clust','k','experiment_name'],keep='last',inplace=True)\n",
    "    \n",
    "    experiment_name, som_dim, n_clust = best_clusters.loc[n_best-1,['experiment_name','som_dim','n_clust']]    \n",
    "    val = best_centroids['n_clust'].max()\n",
    "    \n",
    "    data = best_centroids.set_index(['experiment_name','som_dim','n_clust','k'])\n",
    "    data.sort_index(level=['experiment_name','som_dim','n_clust'], inplace=True)\n",
    "    traces = data.loc[(experiment_name, som_dim, n_clust), [str(i) for i in range(0,24)]].reset_index(drop=True).T\n",
    "    traces.columns = ['cluster ' + str(k+1) for k in traces.columns.values]\n",
    "    \n",
    "    clust_size = data.loc[(experiment_name, som_dim, n_clust), 'cluster_size'].reset_index(drop=True)\n",
    "    largest = 'cluster '+str(clust_size.idxmax()+1)\n",
    "    \n",
    "    colours = cl.interp(cl.scales['12']['qual']['Paired'], 100)[:n_clust]\n",
    "    \n",
    "    fig = tools.make_subplots(rows=3, cols=1, shared_xaxes=False, specs=[[{'rowspan': 2}],[None],[{}]],\n",
    "                              subplot_titles=['cluster profiles '+experiment_name+' (n='+str(n_clust)+') TOP '+str(n_best),'cluster sizes'], print_grid=False)  \n",
    "    i = 0\n",
    "    for col in traces.columns:\n",
    "        if col == largest:\n",
    "            width = 3\n",
    "        else:\n",
    "            width = 1\n",
    "        fig.append_trace({'x': traces.index, 'y': traces[col], 'line':{'color':colours[i],'width':width}, 'type': 'scatter', 'name': col}, 1, 1)\n",
    "        i+=1\n",
    "    fig.append_trace({'x': traces.columns, 'y': clust_size, 'type': 'bar', 'name': str(n_clust)+' clusters'} , 3, 1)\n",
    "    \n",
    "    fig['layout']['xaxis1'].update(title='time of day')\n",
    "    fig['layout']['xaxis2'].update(tickangle=270)\n",
    "    fig['layout']['yaxis1'].update(title='normalised load profile')\n",
    "    fig['layout']['yaxis2'].update(title='profile count')\n",
    "    fig['layout']['margin'].update(t=50,r=80,b=100,l=90,pad=10),\n",
    "    fig['layout'].update(height=700, hovermode = \"closest\")\n",
    "    \n",
    "    po.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Cluster Label Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_experiments = list(best_clusters.experiment_name.unique())\n",
    "label_files = dict(zip(best_experiments,[e+'_labels.feather' for e in best_experiments]))\n",
    "labels = {}\n",
    "for k, v in label_files.items():\n",
    "    labels[k] = feather.read_dataframe(os.path.join(data_dir, 'cluster_results', v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demin_labels = ce.bestLabels('exp2_kmeans_demin')\n",
    "zerone_labels = ce.bestLabels('exp2_kmeans_zero-one')\n",
    "sanorm_labels = ce.bestLabels('exp2_kmeans_sa_norm')\n",
    "norm_labels = ce.bestLabels('exp2_norm_kmeans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demin_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotClusterLabels(label_data, year, n_clust=None, som_dim=0):\n",
    "    \n",
    "    if n_clust is None:\n",
    "        c = label_data.columns[0]\n",
    "    else:\n",
    "        c = str(som_dim)+'_'+str(n_clust)\n",
    "    df = label_data.loc[pd.IndexSlice[:,str(year)],[c]].reset_index()\n",
    "    df.date = df.date.dt.date\n",
    "    \n",
    "    fig = df.iplot(kind='heatmap', title='Daily cluster labels for profiles in '+str(year)+\n",
    "                   ' (cluster ='+c+')', x='date', y='ProfileID', z=c, colorscale='spectral', asFigure=True)\n",
    "\n",
    "    fig['layout']['yaxis'].update(dict(type='category',title='ProfileID'))\n",
    "    fig['layout']['xaxis'].update(dict(title='Date'))\n",
    "    for i, trace in enumerate(fig['data']):\n",
    "        hovertext = list()\n",
    "        for j in range(len(trace['x'])):\n",
    "            hovertext.append('date: {}<br />cluster label: {}<br />ProfileID: {}<br />'.format(trace['x'][j], trace['z'][j]+1, trace['y'][j]))\n",
    "        trace['text'] = hovertext\n",
    "        trace['hoverinfo']='text'\n",
    "    \n",
    "    return po.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotClusterLabels(sanorm_labels, 2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cmap(cmap): #Display  a colormap cmap\n",
    "    plt.imshow(np.linspace(0, 100, 256)[None, :],  aspect=25, interpolation='nearest', cmap=cmap) \n",
    "    plt.axis('off')\n",
    "    \n",
    "def colormap_to_colorscale(cmap):\n",
    "    #function that transforms a matplotlib colormap to a Plotly colorscale\n",
    "    return [ [k*0.1, colors.rgb2hex(cmap(k*0.1))] for k in range(11)]\n",
    "\n",
    "def colorscale_from_list(alist, name): \n",
    "    # Defines a colormap, and the corresponding Plotly colorscale from the list alist\n",
    "    # alist=the list of basic colors\n",
    "    # name is the name of the corresponding matplotlib colormap\n",
    "    \n",
    "    cmap = LinearSegmentedColormap.from_list(name, alist)\n",
    "#    display_cmap(cmap)\n",
    "    colorscale=colormap_to_colorscale(cmap)\n",
    "    return cmap, colorscale\n",
    "\n",
    "def normalize(x,a,b): #maps  the interval [a,b]  to [0,1]\n",
    "    if a>=b:\n",
    "        raise ValueError('(a,b) is not an interval')\n",
    "    return float(x-a)/(b-a)\n",
    "\n",
    "def asymmetric_colorscale(data,  div_cmap, ref_point=0.0, step=0.05):\n",
    "    #data: data can be a DataFrame, list of equal length lists, np.array, np.ma.array\n",
    "    #div_cmap is the symmetric diverging matplotlib or custom colormap\n",
    "    #ref_point:  reference point\n",
    "    #step:  is step size for t in [0,1] to evaluate the colormap at t\n",
    "   \n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        D = data.values\n",
    "    elif isinstance(data, np.ma.core.MaskedArray):\n",
    "        D=np.ma.copy(data)\n",
    "    else:    \n",
    "        D=np.asarray(data, dtype=np.float) \n",
    "    \n",
    "    dmin=np.nanmin(D)\n",
    "    dmax=np.nanmax(D)\n",
    "    if not (dmin < ref_point < dmax):\n",
    "        raise ValueError('data are not appropriate for a diverging colormap')\n",
    "        \n",
    "    if dmax+dmin > 2.0*ref_point:\n",
    "        left=2*ref_point-dmax\n",
    "        right=dmax\n",
    "        \n",
    "        s=normalize(dmin, left,right)\n",
    "        refp_norm=normalize(ref_point, left, right)# normalize reference point\n",
    "        \n",
    "        T=np.arange(refp_norm, s, -step).tolist()+[s]\n",
    "        T=T[::-1]+np.arange(refp_norm+step, 1, step).tolist()\n",
    "        \n",
    "        \n",
    "    else: \n",
    "        left=dmin\n",
    "        right=2*ref_point-dmin\n",
    "        \n",
    "        s=normalize(dmax, left,right) \n",
    "        refp_norm=normalize(ref_point, left, right)\n",
    "        \n",
    "        T=np.arange(refp_norm, 0, -step).tolist()+[0]\n",
    "        T=T[::-1]+np.arange(refp_norm+step, s, step).tolist()+[s]\n",
    "        \n",
    "    L=len(T)\n",
    "    T_norm=[normalize(T[k],T[0],T[-1]) for k in range(L)] #normalize T values  \n",
    "    return [[T_norm[k], colors.rgb2hex(div_cmap(T[k]))] for k in range(L)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plotClusterSpecificity(data, corr_list, n_clust=None):\n",
    "    \n",
    "    print('n_clust options: \\n', data.columns.values)\n",
    "    \n",
    "    if n_clust is None:\n",
    "        n_clust = data.columns[0]\n",
    "\n",
    "    n_corr = len(corr_list)    \n",
    "    \n",
    "    #Create dataframes for plot\n",
    "#    df = data.reset_index()\n",
    "    \n",
    "    subplt_titls = ()\n",
    "    titles = []\n",
    "    for corr in corr_list:\n",
    "        title = '\"Greater than random\" probability of '+corr+' assigned to cluster'\n",
    "        titles.append((title, None))    \n",
    "    for t in titles:\n",
    "        subplt_titls += t\n",
    "    \n",
    "    #Initialise plot\n",
    "    fig = tools.make_subplots(rows=n_corr, cols=2, shared_xaxes=False, print_grid=False, \n",
    "                              subplot_titles=subplt_titls)\n",
    "    #Create colour scale\n",
    "    smarties = cl.scales['5']['div']['Spectral']\n",
    "    slatered=['#232c2e', '#ffffff','#c34513']\n",
    "    label_cmap, label_cs = colorscale_from_list(slatered, 'label_cmap') \n",
    "    \n",
    "    i = 1\n",
    "    for corr in corr_list:\n",
    "        function = 'ce.'+corr+'_corr(data, n_clust)'\n",
    "        rndm_lklhd, lbls2 = eval(function)   \n",
    "\n",
    "        #Create colorscales\n",
    "        colorscl= asymmetric_colorscale(lbls2, label_cmap, ref_point=1.0)\n",
    "#        colorscl=[[0.0, 'rgb(112,138,144)'],[white, 'rgb(255,255,255)'],[1.0, 'rgb(239,138,98)']]\n",
    "\n",
    "        #Create traces\n",
    "        heatmap = go.Heatmap(z = lbls2.T.values, x = lbls2.index, y = lbls2.columns, name = corr, \n",
    "                          colorscale=colorscl, colorbar=dict(title='likelihood',len=0.9/n_corr, y= 1-i/n_corr+0.05/i, yanchor='bottom'))\n",
    "        bargraph = lbls2.iplot(kind='bar', colors=smarties, showlegend=False, asFigure=True)\n",
    "\n",
    "        fig.append_trace(heatmap, i, 1)\n",
    "        for b in bargraph['data']:\n",
    "            fig.append_trace(b, i, 2)\n",
    "        random_likelihood=dict(type='scatter', x=[lbls2.index[0], lbls2.index[-1]], y=[1, 1], \n",
    "                                       mode='lines', line=dict(color='black',dash='dash'))\n",
    "        fig.append_trace(random_likelihood, i, 2)\n",
    "        \n",
    "        fig['layout']['yaxis'+str(i*2)].update(title='greater than random Passignment')\n",
    "        fig['layout']['annotations'].extend([dict(x = lbls2.index[int(len(lbls2.index)*0.5)], y = 1, showarrow=True, yshift=5,\n",
    "                                              text=\"random assignment\",ax=10, ay=-70, xref='x'+str(i*2), yref='y'+str(i*2))])\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    #Update layout\n",
    "    fig['layout'].update(title='Temporal specificity of k clusters', height=n_corr*400, hovermode = \"closest\", showlegend=False) \n",
    "\n",
    "    po.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rndm_lklhd, lbls2 = ce.weekday_corr(sanorm_labels, '0_17')\n",
    "lbls2.iplot(kind='heatmap',colorscale='RdGy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Clusters and Label Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotClusterCentroids(sanorm_clusters)\n",
    "plotClusterSpecificity(sanorm_labels, corr_list=['daytype','weekday','month','season','year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotClusterCentroids(best_clusters)\n",
    "#plotClusterSpecificity(norm_labels, corr_list=['daytype','weekday','month','season','year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotClusterCentroids(demin_clusters)\n",
    "plotClusterSpecificity(demin_labels, corr_list=['daytype','weekday','month','season','year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotClusterCentroids(zerone_clusters)\n",
    "plotClusterSpecificity(zerone_labels, corr_list=['daytype','weekday','month','season','year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising Daily Demand Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int100_likelihood, q100_likelihood = ce.demandCorr('exp2_norm_kmeans', '0_47')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Equally spaced daily demand intervals\n",
    "i = int100_likelihood.stack().reset_index()\n",
    "i.columns = ['int100_bins', 'cluster', 'values']\n",
    "fig = i.iplot(kind='heatmap', x = 'int100_bins', y='cluster', z='values', colorscale='Reds', \n",
    "              title= 'Heatmap of relative likelihood of Cluster k being used in consumption bin', asFigure=True)\n",
    "fig['layout']['xaxis'].update(dict(title = 'total daily demand bins (Amps)', \n",
    "                                   tickmode='array', tickvals=list(range(0,100,10)), ticktext = list(range(0,1000,100))))\n",
    "fig['layout']['yaxis'].update(dict(title='Cluster k'))\n",
    "po.iplot(fig)\n",
    "\n",
    "#Equally sized daily demand intervals (quantiles)\n",
    "rel_q100 = q100_likelihood.drop(columns='Cluster 33')/0.01\n",
    "\n",
    "slatered=['#232c2e', '#ffffff','#c34513']\n",
    "label_cmap, label_cs = colorscale_from_list(slatered, 'label_cmap') \n",
    "colorscl= asymmetric_colorscale(rel_q100, label_cmap, ref_point=1.0)\n",
    "\n",
    "heatmap = go.Heatmap(z = rel_q100.T.values, x = rel_q100.index, y = rel_q100.columns, name = 'corr', \n",
    "                          colorscale=colorscl)\n",
    "layout = go.Layout(\n",
    "        title= 'Heatmap of relative likelihood of Cluster k being used in consumption quantile',\n",
    "        xaxis=dict(title = 'total daily demand quantiles (Amps) - log scale', type='log'),\n",
    "        yaxis=dict(title ='Cluster k'))\n",
    "fig = {'data':[heatmap], 'layout':layout }\n",
    "po.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
