{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Load Profile Timeseries Clustering Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "from math import ceil\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.offline as po\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.tools as tools\n",
    "import colorlover as cl\n",
    "#from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "\n",
    "import matplotlib. pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import evaluation.eval_clusters as ec\n",
    "import evaluation.eval_cluster_plot as pc\n",
    "from support import data_dir\n",
    "eval_dir = os.path.join(data_dir,'cluster_evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = ec.getExperiments('exp')\n",
    "exp2 = ec.getExperiments('exp2')\n",
    "exp3 = ec.getExperiments('exp3')\n",
    "exp4 = ec.getExperiments('exp4')\n",
    "exp5 = ec.getExperiments('exp5')\n",
    "exp6 = ec.getExperiments('exp6')\n",
    "#experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Cluster Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Davies-Bouldin Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterIndex('dbi', 'Davies-Bouldin Index', experiments, groupby='algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Index Adequacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterIndex('mia','Mean Index Adequacy', experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette Score\n",
    "\n",
    "The best value is 1 and the worst value is -1. Values near 0 indicate overlapping clusters. Negative values generally indicate that a sample has been assigned to the wrong cluster, as a different cluster is more similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterIndex('silhouette', 'Silhouette Score', experiments, groupby='algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Cluster Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterIndex('score','Combined Cluster Score', experiments, groupby='algorithm', ylog=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Cluster Labels, Centroids and Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select best clusters for different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results = ec.readResults()\n",
    "\n",
    "selected_clusters = dict()\n",
    "for e in experiments:\n",
    "    clusters = ec.selectClusters(cluster_results, 5, threshold=2000, experiment=e)\n",
    "    selected_clusters[e] = clusters\n",
    "selected_clusters['best'] = ec.selectClusters(cluster_results, 10, threshold=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected_clusters['best']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Cluster Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_exp = ['exp2_kmeans_unit_norm', 'exp5_kmeans_unit_norm', 'exp6_kmeans_unit_norm']\n",
    "            #'exp6_kmeans_demin', 'exp2_kmeans_demin',]\n",
    "            #'exp4_kmeans_zero-one', 'exp5_kmeans_zero-one']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = dict()\n",
    "for e in best_exp[-1:]:\n",
    "    labels = ec.getLabels(e)\n",
    "    cluster_labels[e] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get denormalised (real) cluster centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_cluster_centroids = dict()\n",
    "\n",
    "for e in best_exp:\n",
    "    rccpath = os.path.join(eval_dir, 'best_centroids', e +'BEST1_centroids.csv')\n",
    "    centroids  = pd.read_csv(rccpath, index_col='k')\n",
    "    real_cluster_centroids[e] = centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_cluster_centroids['exp2_kmeans_unit_norm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get normalised cluster centroids \n",
    "#### only for exp2 & exp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cluster_centroids = dict()\n",
    "for k, v in selected_clusters.items():\n",
    "    name = k\n",
    "    centroids, cs, meta  = ec.getCentroids(v)\n",
    "    norm_cluster_centroids[name] = {'centroids':centroids, 'cluster_size':cs, 'description':meta}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec.exploreAMDBins(cluster_results, 'exp5_kmeans_unit_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec.exploreAMDBins(cluster_results, 'exp6_kmeans_unit_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "pc.plotClusterCentroids(real_cluster_centroids[best_exp[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Patterns in Cluster Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Cluster Label Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterLabels(list(cluster_labels.values())[2], 2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise TEMPORAL Cluster Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pc.plotClusterSpecificity(list(cluster_labels.values())[1], corr_list=['daytype','weekday','monthly','season','yearly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise CONTEXTUAL Cluster Specificity (Daily Demand Assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "context = ['demandi','demandq']\n",
    "\n",
    "int100_likelihood, q100_likelihood = ec.demandCorr(list(cluster_labels.values())[1], compare='total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Equally spaced daily demand intervals\n",
    "i = int100_likelihood.stack().reset_index()\n",
    "i.columns = ['int100_bins', 'cluster', 'values']\n",
    "fig = i.iplot(kind='heatmap', x = 'int100_bins', y='cluster', z='values', colorscale='Reds', \n",
    "              title= 'Heatmap of relative likelihood of Cluster k being used in consumption bin', asFigure=True)\n",
    "fig['layout']['xaxis'].update(dict(title = 'total daily demand bins (Amps)', \n",
    "                                   tickmode='array', tickvals=list(range(0,100,10)), ticktext = list(range(0,1000,100))))\n",
    "fig['layout']['yaxis'].update(dict(title='Cluster k'))\n",
    "po.iplot(fig)\n",
    "\n",
    "#Equally sized daily demand intervals (quantiles)\n",
    "rel_q100 = q100_likelihood.drop(columns='Cluster 33')/0.01\n",
    "\n",
    "slatered=['#232c2e', '#ffffff','#c34513']\n",
    "label_cmap, label_cs = pc.colorscale_from_list(slatered, 'label_cmap') \n",
    "colorscl= pc.asymmetric_colorscale(rel_q100, label_cmap, ref_point=1.0)\n",
    "\n",
    "heatmap = go.Heatmap(z = rel_q100.T.values, x = rel_q100.index, y = rel_q100.columns, name = 'corr', \n",
    "                          colorscale=colorscl)\n",
    "layout = go.Layout(\n",
    "        title= 'Heatmap of relative likelihood of Cluster k being used in consumption quantile',\n",
    "        xaxis=dict(title = 'total daily demand quantiles (Amps) - log scale', type='log'),\n",
    "        yaxis=dict(title ='Cluster k'))\n",
    "fig = {'data':[heatmap], 'layout':layout }\n",
    "po.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Cluster Representativity and Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_consE, peak_consE, peak_coincR, temporal_entropy, context_entropy = ec.getMeasures(best_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumption Error - total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterMetrics(total_consE, 'TOTAL consumption error evaluation metrics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumption Error - max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterMetrics(peak_consE, 'PEAK consumption error evaluation metrics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak Coincidence Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterMetrics(peak_coincR, 'daily peak coincidence ratios', metric='coincidence_ratio', make_area_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Entropy - TEMPORAL\n",
    "#### weekday, month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterMetrics(temporal_entropy, 'time-derived cluster entropy')#, metric='weekday_entropy', make_area_plot=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Entropy - CONTEXTUAL\n",
    "#### total daily demand, max daily demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterMetrics(context_entropy, 'context-derived cluster entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ec.saveMeasures(best_exp)\n",
    "pd.read_csv(os.path.join(eval_dir,'cluster_entropy.csv'), index_col=[0,1], header=[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
