{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Load Profile Timeseries Clustering Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from math import ceil\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.offline as po\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.tools as tools\n",
    "import colorlover as cl\n",
    "#from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "\n",
    "import matplotlib. pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import evaluation.evalClusters as ec\n",
    "import evaluation.plotClusters as pc\n",
    "\n",
    "experiments = ['exp2_kmeans_demin','exp2_kmeans_zero-one','exp2_kmeans_sa_norm','exp2_norm_kmeans']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Cluster Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Davies-Bouldin Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterIndex('dbi', 'Davies-Bouldin Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Index Adequacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterIndex('mia','Mean Index Adequacy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette Score\n",
    "\n",
    "The best value is 1 and the worst value is -1. Values near 0 indicate overlapping clusters. Negative values generally indicate that a sample has been assigned to the wrong cluster, as a different cluster is more similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterIndex('silhouette', 'Silhouette Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Cluster Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterIndex('score','Combined Cluster Score',ylog=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Cluster Centroids and Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select best clusters for different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results = ec.readResults()\n",
    "\n",
    "selected_clusters = dict()\n",
    "for e in experiments:\n",
    "    name = e.split('_',1)[1]\n",
    "    clusters  = ec.selectClusters(cluster_results, 5, e)\n",
    "    selected_clusters[name] = clusters\n",
    "selected_clusters['best'] = ec.selectClusters(cluster_results, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get normalised cluster centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cluster_centroids = dict()\n",
    "for k, v in selected_clusters.items():\n",
    "    name = k\n",
    "    centroids, cs, meta  = ec.getCentroids(v)\n",
    "    norm_cluster_centroids[name] = {'centroids':centroids,'cluster_size':cs, 'description':meta}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get denormalised (real) cluster centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_cluster_centroids = dict()\n",
    "for e in experiments:\n",
    "    name = e.split('_',1)[1]\n",
    "    centroids, cs, meta  = ec.realCentroids(e)\n",
    "    real_cluster_centroids[name] = {'centroids':centroids,'cluster_size':cs, 'description':meta}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterCentroids(list(real_cluster_centroids.values())[3]['centroids'], \n",
    "                        list(real_cluster_centroids.values())[3]['cluster_size'], \n",
    "                        list(real_cluster_centroids.values())[3]['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Patterns in Cluster Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = dict()\n",
    "for e in experiments:\n",
    "    name = e.split('_',1)[1]\n",
    "    labels = ec.bestLabels(e)\n",
    "    cluster_labels[name] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Cluster Label Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterLabels(list(cluster_labels.values())[0], 2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise TEMPORAL Cluster Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pc.plotClusterSpecificity(list(cluster_labels.values())[0], corr_list=['daytype','weekday','monthly','season','yearly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise CONTEXTUAL Cluster Specificity (Daily Demand Assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "int100_likelihood, q100_likelihood = ec.demandCorr('exp2_norm_kmeans', compare='total', n_best=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Equally spaced daily demand intervals\n",
    "i = int100_likelihood.stack().reset_index()\n",
    "i.columns = ['int100_bins', 'cluster', 'values']\n",
    "fig = i.iplot(kind='heatmap', x = 'int100_bins', y='cluster', z='values', colorscale='Reds', \n",
    "              title= 'Heatmap of relative likelihood of Cluster k being used in consumption bin', asFigure=True)\n",
    "fig['layout']['xaxis'].update(dict(title = 'total daily demand bins (Amps)', \n",
    "                                   tickmode='array', tickvals=list(range(0,100,10)), ticktext = list(range(0,1000,100))))\n",
    "fig['layout']['yaxis'].update(dict(title='Cluster k'))\n",
    "po.iplot(fig)\n",
    "\n",
    "#Equally sized daily demand intervals (quantiles)\n",
    "rel_q100 = q100_likelihood.drop(columns='Cluster 33')/0.01\n",
    "\n",
    "slatered=['#232c2e', '#ffffff','#c34513']\n",
    "label_cmap, label_cs = pc.colorscale_from_list(slatered, 'label_cmap') \n",
    "colorscl= pc.asymmetric_colorscale(rel_q100, label_cmap, ref_point=1.0)\n",
    "\n",
    "heatmap = go.Heatmap(z = rel_q100.T.values, x = rel_q100.index, y = rel_q100.columns, name = 'corr', \n",
    "                          colorscale=colorscl)\n",
    "layout = go.Layout(\n",
    "        title= 'Heatmap of relative likelihood of Cluster k being used in consumption quantile',\n",
    "        xaxis=dict(title = 'total daily demand quantiles (Amps) - log scale', type='log'),\n",
    "        yaxis=dict(title ='Cluster k'))\n",
    "fig = {'data':[heatmap], 'layout':layout }\n",
    "po.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Cluster Representativity and Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumption Error - total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_consE = dict()\n",
    "for e in experiments:\n",
    "    name = e.split('_',1)[1]\n",
    "    mape, mdape, mdlq, mdsyma = ec.consumptionError(e, compare='total', n_best=1)\n",
    "    total_consE[name] = {'mape':mape,'mdape':mdape,'mdlq':mdlq,'mdsyma':mdsyma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterMetrics(total_consE, 'TOTAL consumption error evaluation metrics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumption Error - max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_consE = dict()\n",
    "for e in experiments:\n",
    "    name = e.split('_',1)[1]\n",
    "    mape, mdape, mdlq, mdsyma = ec.consumptionError(e, compare='peak', n_best=1)\n",
    "    peak_consE[name] = {'mape':mape,'mdape':mdape,'mdlq':mdlq,'mdsyma':mdsyma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterMetrics(peak_consE, 'PEAK consumption error evaluation metrics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak Coincidence Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_coincR = dict()\n",
    "for e in experiments:\n",
    "    name = e.split('_',1)[1]\n",
    "    peak_eval = ec.peakCoincidence(e, n_best=1).reset_index(drop=True)\n",
    "    peak_coincR[name] = {'coincidence_ratio':peak_eval['coincidence_ratio']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterMetrics(peak_coincR, 'daily peak coincidence ratios', metric='coincidence_ratio', make_area_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Entropy - TEMPORAL\n",
    "#### weekday, month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_entropy = dict()\n",
    "max_entropy = dict()\n",
    "\n",
    "for k,l in cluster_labels.items():\n",
    "    weekday_likelihood, relative_likelihood = ec.weekdayCorr(l)\n",
    "    monthly_likelihood, relative_likelihood = ec.monthlyCorr(l)\n",
    "    \n",
    "    wce, wme = ec.clusterEntropy(weekday_likelihood, random_likelihood=None)\n",
    "    mce, mme = ec.clusterEntropy(monthly_likelihood, random_likelihood=None)\n",
    "    \n",
    "    temporal_entropy[k] = {'weekday_entropy':wce.reset_index(drop=True),'monthly_entropy':mce.reset_index(drop=True)}\n",
    "    max_entropy[k] = {'weekday_entropy':wme,'monthly_entropy':mme}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterMetrics(temporal_entropy, 'time-derived cluster entropy', metric='weekday_entropy', make_area_plot=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Entropy - CONTEXTUAL\n",
    "#### total daily demand, max daily demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_entropy = dict()\n",
    "\n",
    "for e in experiments:\n",
    "    name = e.split('_',1)[1]\n",
    "    total_int, total_q = ec.demandCorr(e, compare='total', n_best=1)\n",
    "    peak_int, peak_q = ec.demandCorr(e, compare='peak', n_best=1)\n",
    "   \n",
    "    ice, ime = ec.clusterEntropy(total_int, random_likelihood=None)\n",
    "    pce, pme = ec.clusterEntropy(peak_int, random_likelihood=None)\n",
    "    \n",
    "    context_entropy[name] = {'total_entropy':ice.reset_index(drop=True),'peak_entropy':pce.reset_index(drop=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.plotClusterMetrics(context_entropy, 'context-derived cluster entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = ['total_consE', 'peak_consE', 'peak_coincR', 'temporal_entropy', 'context_entropy']\n",
    "mean_measures = list()\n",
    "\n",
    "for m in measures:\n",
    "    m_data = eval(m)\n",
    "    for k,v in m_data.items():\n",
    "        for i,j in v.items():\n",
    "            me = ec.meanError(j)\n",
    "            mean_measures.append([m,k, i, me])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_table = pd.DataFrame(mean_measures, columns=['measure','experiment','metric','value'])\n",
    "evalcrit = evaluation_table.measure.apply(lambda x: x.split('_',1)[1])\n",
    "evaluation_table.insert(0, 'evaluation_criteria', evalcrit)\n",
    "evaluation_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dict = []\n",
    "for index, row in evaluation_table.iterrows(): \n",
    "    r = dict(zip(list(evaluation_table.columns),row.values))\n",
    "    mean_dict.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#et = evaluation_table.set_index(['evaluation_criteria','experiment','measure','metric']).unstack(level=['evaluation_criteria','measure','metric'])\n",
    "et = evaluation_table.set_index(['evaluation_criteria','experiment','measure','metric']).unstack(level=['experiment'])\n",
    "et"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
